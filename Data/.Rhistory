sum.fit4
boston$medv
length(boston$medv)
length(z)
plot(boston.t1$medv,sum.fit4)
length(boston.t1$medv)
length(z)
shapiro.test(sum.fit4$residuals)
#We can reject the null hypothesis and confirm the normality assumption as
#we have a small p-value(8.13e-16).
z<-rstudent(fit4)
plot(boston.t1$medv,sum.fit4)
x<-boston.t1$medv
plot(boston.t1$medv,sum.fit4)
plot(x,z)
shapiro.test(sum.fit4$residuals)
#We can reject the null hypothesis and confirm the normality assumption as
#we have a small p-value(8.13e-16).
z<-rstudent(fit4)
x<-boston.t1$medv
plot(x,z, xlim=c(0,45))
abline(h=0,col=2,lwd=2)
abline(h=2, col=3,lwd=2, lty=2)
abline(h=-2,col=3,lwd=2, lty=2)
influencePlot(fit4,main="Influence Plot", xlab="Circle size
is proportial to Cook's Distance")
ncvTest(fit4)
#Due to a small p-value we can see that homoscedasticity is present.
spreadLevelPlot(fit4)
vif(fit4)
fit5<-lm(medv~.-indus-age-zn+rm*lstat-b-rad+rm*rad,data=boston.t1)
summary(fit5)
vif(fit5)
vif(fit4)
fit5<-lm(medv~.-indus-age-zn+-b-rad,data=boston.t1)
summary(fit5)
#There is evidence of multicollinearity
boxTidwell(fit4)
#There is evidence of multicollinearity
boxTidwell(lm(medv~.-indus-age-zn+rm*lstat-b+rm*rad+lstat*rad,data=boston.t1))
#There is evidence of multicollinearity
boxTidwell(medv~.-indus-age-zn+rm*lstat-b+rm*rad+lstat*rad,data=boston.t1)
View(BostonHousing)
View(boston.t2)
#There is evidence of multicollinearity
boxTidwell(medv~.-indus-age-zn-chas+rm*lstat-b+rm*rad+lstat*rad,data=boston.t1)
#There is evidence of multicollinearity
summary(powerTransform(boston.t1$crim)
#There is evidence of multicollinearity
summary(powerTransform(boston.t1$crim))
summary(powerTransform(boston.t1$crim))
vif(fit4)
vif(fit2)
shapiro.test(sum.fit2$residuals)
#We can reject the null hypothesis and confirm the normality assumption as
#we have a small p-value(8.13e-16).
z<-rstudent(fit2)
x<-boston.t1$medv
plot(x,z, xlim=c(0,45))
abline(h=0,col=2,lwd=2)
abline(h=2, col=3,lwd=2, lty=2)
abline(h=-2,col=3,lwd=2, lty=2)
influencePlot(fit2,main="Influence Plot", xlab="Circle size
is proportial to Cook's Distance")
ncvTest(fit2)
spreadLevelPlot(fit2)
#Due to a small p-value we can see that homoscedasticity is present.
spreadLevelPlot(fit4)
#Here we can see 95% confidence intervals for each of the coefficients
AIC(fit4)
AIC(fit3)
AIC(fit2)
AIC(fit1)
#We can see that fit 4 has a smaller AIC value than fit2. Fit2 was a the most
#competing model to fit 4.
fit4$coefficients
fit5<- glm(medv~.,family=binomial (link = "logit"), data=boston.t1)
fit5<- glm(medv~.,family=gaussian(link = "identity"), data=boston.t1)
fit5
#Here we can see 95% confidence intervals for each of the coefficients
AIC(fit4)
#Here we can see 95% confidence intervals for each of the coefficients
AIC(fit4)
fit5<- glm(medv~.,family=gamma(link = "inverse"), data=boston.t1)
fit5<- glm(medv~.,family=inverse.gamma(link = "1/mu^2"), data=boston.t1)
fit5<- glm(medv~.,family=poisson(link = "log"), data=boston.t1)
fit5
fit5<- glm(medv~.,family=quasi (link = "identity", variance = "constant"), data=boston.t1)
fit5
fit5<- glm(medv~.,family=quasibinomial (link = "logit"), data=boston.t1)
fit5<- glm(medv~.,family=quasipoisson (link = "log"), data=boston.t1)
fit5
fit5<- glm(medv~.,family=quasipoisson (link = "log"), data=boston.t1)
fit5
fit6<-glm(medv~.,family=guassian (link = "identity"), data=boston.t1)
fit5<- glm(medv~.,family=quasipoisson (link = "log"), data=boston.t1)
fit5
fit6<-glm(medv~.,family=gaussian (link = "identity"), data=boston.t1)
fit6
fit7<- glm(medv~.,family=gamma(link = "inverse"), data=boston.t1)
fit5<- glm(medv~.,family=quasipoisson (link = "log"), data=boston.t1)
fit5
fit6<-glm(medv~.,family=gaussian (link = "identity"), data=boston.t1)
fit6
fit7<- glm(medv~.,family=inverse.gaussian(link = "1/mu^2"), data=boston.t1)
fit7
fit8<- glm(medv~.,family=poisson (link = "log"), data=boston.t1)
fit8
AIC(fit5)
chisq.test(fit4)
deviance(fit4)/df.residual(fit4)
#Here we can see 95% confidence intervals for each of the coefficients
fit4$coefficients
#Due to a small p-value we can see that homoscedasticity is present.
spreadLevelPlot(fit4)
fit3 <- lm(medv~.-indus-age+rm*lstat+rm*rad+lstat*rad,data=boston.t1)
sum.fit3<-summary(fit3)
sum.fit3
iqr <- IQR(BostonHousing$crim)
BostonHousing$crim1<- subset(BostonHousing, BostonHousing$crim > (Q[1] - 1.5*iqr) & BostonHousing$crim < (Q[2]+1.5*iqr))
Q <- quantile(warpbreaks$breaks, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(BostonHousing$crim)
BostonHousing$crim1<- subset(BostonHousing, BostonHousing$crim > (Q[1] - 1.5*iqr) & BostonHousing$crim < (Q[2]+1.5*iqr))
View(BostonHousing)
Q <- quantile(warpbreaks$breaks, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(BostonHousing$crim)
BostonHousing$crim1 <- NA
BostonHousing$crim1<- subset(BostonHousing, BostonHousing$crim > (Q[1] - 1.5*iqr) & BostonHousing$crim < (Q[2]+1.5*iqr))
BostonHousing$crim1 <- NA
BostonHousing$crim1 <- 1
View(BostonHousing)
data(BostonHousing)
library(mlbench)
data(BostonHousing)
dim(BostonHousing)
head(BostonHousing)
BostonHousing$crim1 <- NA
Q <- quantile(warpbreaks$breaks, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(BostonHousing$crim)
BostonHousing$crim1 <- NA
BostonHousing$crim1<- subset(BostonHousing, BostonHousing$crim > (Q[1] - 1.5*iqr) & BostonHousing$crim < (Q[2]+1.5*iqr))
data(BostonHousing)
Q <- quantile(warpbreaks$breaks, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(BostonHousing$crim)
BostonHousing$crim1 <- NA
BostonHousing$crim1 <- BostonHousing[BostonHousing$crim > quantile(BostonHousing$crim, .25) - 1.5*IQR(BostonHousing$crim) &
BostonHousing$crim < quantile(BostonHousing$crim, .75) + 1.5*IQR(BostonHousing$crim), ]
Q <- quantile(warpbreaks$breaks, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(BostonHousing$crim)
BostonHousing$crim1 <- NA
crim1 <- BostonHousing[BostonHousing$crim > quantile(BostonHousing$crim, .25) - 1.5*IQR(BostonHousing$crim) &
BostonHousing$crim < quantile(BostonHousing$crim, .75) + 1.5*IQR(BostonHousing$crim), ]
View(crim1)
data(BostonHousing)
Q <- quantile(warpbreaks$breaks, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(BostonHousing$crim)
BostonHousing$crim <- BostonHousing[BostonHousing$crim > quantile(BostonHousing$crim, .25) - 1.5*IQR(BostonHousing$crim) &
BostonHousing$crim < quantile(BostonHousing$crim, .75) + 1.5*IQR(BostonHousing$crim), ]
Q1 <- quantile(BostonHousing$crim, .25)
Q3 <- quantile(BostonHousing$crim, .75)
IQR <- IQR(BostonHousing$crim)
#only keep rows in dataframe that have values within 1.5*IQR of Q1 and Q3
no_outliers <- subset(BostonHousing, BostonHousing$crim> (Q1 - 1.5*IQR) & BostonHousing$crim< (Q3 + 1.5*IQR))
#view row and column count of new data frame
dim(no_outliers)
boxplot(no_outliers$crim)
boxplot(no_outliers)
ncvTest(fit4)
#Here we can see 95% confidence intervals for each of the coefficients
fit4$coefficients
knitr::opts_chunk$set(echo = TRUE)
sum.fit3
knitr::opts_chunk$set(echo = TRUE)
library(mlbench)
zebra<- data("BostonHousing")
zebra<- data(BostonHousing)
zebra<- data(BostonHousing)
zebra<- data.frame(BostonHousing)
scale(zebra)
zebra2<- data.frame(BostonHousing[-chas])
zebra2<- data.frame(BostonHousing[-4])
View(zebra2)
scale(zebra2)
boxplot(zebra2)
x<-scale(zebra2)
knitr::opts_chunk$set(echo = TRUE)
#We can reject the null hypothesis and confirm the normality assumption as
#we have a small p-value(8.13e-16).
z<-rstudent(fit4)
#We can reject the null hypothesis and confirm the normality assumption as
#we have a small p-value(8.13e-16).
z<-rstudent(fit4)
x<-boston.t1$medv
library(mlbench)
zebra<- data.frame(BostonHousing)
zebra2<- data.frame(BostonHousing[-4])
x<-scale(zebra2)
boxplot(zebra2)
zebra3<- cbind(zebra,x)
zebra4<- cbind(zebra,zebra$chas)
zebra4<- cbind(zebra2,zebra$chas)
library(mlbench)
zebra<- data.frame(BostonHousing)
zebra2<- data.frame(BostonHousing[-4])
x<-scale(zebra2)
zebra4<- cbind(zebra2,zebra$chas)
fit1 <- lm(medv~ ., data = boston.t1)
sum.fit1 <- summary(fit1)
sum.fit1
library(mlbench)
zebra<- data.frame(BostonHousing)
zebra2<- data.frame(BostonHousing[-4])
x<-scale(zebra2)
zebra4<- cbind(zebra2,zebra$chas)
fit1 <- lm(medv~ ., data = zebra4)
sum.fit1 <- summary(fit1)
sum.fit1
summary(fit2)
fit1 <- lm(medv~ ., data = boston.t1)
sum.fit1 <- summary(fit1)
sum.fit1
knitr::opts_chunk$set(echo = TRUE)
plot(x,z, xlim=c(0,45))
shapiro.test(sum.fit4$residuals)
#We can reject the null hypothesis and confirm the normality assumption as
#we have a small p-value(8.13e-16).
z<-rstudent(fit4)
x<-boston.t1$medv
plot(x,z, xlim=c(0,45))
abline(h=0,col=2,lwd=2)
abline(h=2, col=3,lwd=2, lty=2)
abline(h=-2,col=3,lwd=2, lty=2)
influencePlot(fit4,main="Influence Plot", xlab="Circle size
is proportial to Cook's Distance")
boston<- data.frame(BostonHousing)
boston$chas<-as.numeric(boston$chas)
library(corrplot)
library(car)
cor(boston)
corrplot(cor(boston))
scatterplotMatrix(boston, main='Scatter Plot Matrix')
shapiro.test(sum.fit4$residuals)
#We can reject the null hypothesis and confirm the normality assumption as
#we have a small p-value(8.13e-16).
z<-rstudent(fit4)
x<-boston.t1$medv
plot(x,z, xlim=c(0,45))
abline(h=0,col=2,lwd=2)
abline(h=2, col=3,lwd=2, lty=2)
abline(h=-2,col=3,lwd=2, lty=2)
influencePlot(fit4,main="Influence Plot", xlab="Circle size
is proportial to Cook's Distance")
knitr::opts_chunk$set(echo = TRUE)
ncvTest(fit5)
library(corrplot)
library(car)
ncvTest(fit5)
ncvTest(fit6)
ncvTest(fit7)
AIC(fit4)
AIC(fit2)
AIC(fit5)
AIC(fit6)
AIC(fit7)
setwd("C:/Users/micha/OneDrive/R")
knitr::opts_chunk$set(comment = NA, warning=FALSE, message=FALSE)
knitr::opts_chunk$set(out.width="80%")
options(width = 80)
library(ISLR)
data(College)
set.seed(1234)
train <-sample(nrow(College),0.8*nrow(College))
College.train <- College[train,]
College.validate <- College[-train,]
fit.logit<- glm(Private~., data=College.train,family=binomial())
summary(fit.logit)
#3 predictors are significant at the 5% level
logit.fit.reduced <- step(fit.logit,direction = "backward")
#I would suggest the reduced model as the model makes fewer mistakes
#as it excludes variables
prob <- predict(logit.fit.reduced, College.validate, type = "response")
logit.pred <- factor(prob > .5,levels=c(FALSE,TRUE),labels=c("YES","NO"))
table(logit.pred)
logit.perf<-table(College.validate$Private, logit.pred, dnn = c("Actual","Predicted"))
table(logit.perf)
install.packages("rpart")
library(rpart)
library(rpart)
set.seed(1234)
dtree<- rpart(Private~., data=College.train,method="Private",parms = list(split="information"))
library(rpart)
set.seed(1234)
dtree<- rpart(Private~., data=College.train,method="class",parms = list(split="information"))
summary(dtree)
print(dtree)
dtree$cptable
plotcp(dtree)
dtree$cptable
dtree$cptable
plotcp(dtree)
dtree$cptable
dtree.pruned<- prune(dtree,cp=.1065)
dtree.pred<- pred(dtree.pruned,College.validate,type="class")
dtree.pred<- predict(dtree.pruned,College.validate,type="class")
library(rpart)
set.seed(1234)
dtree<- rpart(Private~., data=College.train,method="class",parms = list(split="information"))
dtree$cptable
plotcp(dtree)
dtree.pruned<- prune(dtree,cp=.1065)
dtree.pred<- predict(dtree.pruned,College.validate,type="class")
dtree.perf<-table(College.validate$Private,dtree.pred,
dnn = c("Actual","Predicted"))
dtree.perf
logit.perf
prob <- predict(logit.fit.reduced, College.validate, type = "response")
logit.pred <- factor(prob > .5,levels=c(FALSE,TRUE),labels=c("NO","YES"))
table(logit.pred)
logit.pred
prob <- predict(logit.fit.reduced, College.validate, type = "response")
logit.pred <- factor(prob > .5,levels=c(FALSE,TRUE),labels=c("NO","YES"))
table(logit.pred)
logit.perf<-table(College.validate$Private, logit.pred, dnn = c("Actual","Predicted"))
logit.perf
#There are 7 false positives-classified as No while in reality they are
#T
logit.perf<-table(College.validate$Private, logit.pred, dnn = c("Actual","Predicted"))
logit.perf
#There are 7 false positives-classified as No while in reality they are
#There are 5 false negatives-classified as Yes while in relaity there are not
install.packages("party")
library(party)
fit.ctree<- ctree(Private~., data=College.train)
ctree.pred<- predict(fit.ctree, College.train, type="response")
ctree.perf
library(party)
fit.ctree<- ctree(Private~., data=College.train)
ctree.pred<- predict(fit.ctree, College.train, type="response")
ctree.perf<- table(College.validate$Private,ctree.pred,
dnn=c("Actual","Predicted"))
library(party)
fit.ctree<- ctree(Private~., data=College.train)
ctree.pred<- predict(fit.ctree, College.validate, type="response")
ctree.perf<- table(College.validate$Private,ctree.pred,
dnn=c("Actual","Predicted"))
ctree.perf
ctree.perf
install.packages("randomForest")
library(randomForest)
library(randomForest)
set.seed(1234)
fit.forest<- randomForest(Private~., data=College.train, na.action=na.roughfix,
importance=TRUE)
forest.pred<- predict(fit.forest,College.validate)
forest.perf
library(randomForest)
set.seed(1234)
fit.forest<- randomForest(Private~., data=College.train, na.action=na.roughfix,
importance=TRUE)
forest.pred<- predict(fit.forest,College.validate)
forest.perf<- table(College.validate$Private, forest.pred,
dnn=c("Actual","Predicted"))
forest.perf
performance <- function(table, n=2){
if(!all(dim(table) == c(2,2)))
stop("Must be a 2 x 2 table")
tn = table[1,1]
fp = table[1,2]
fn = table[2,1]
tp = table[2,2]
sensitivity = tp/(tp+fn)
specificity = tn/(tn+fp)
ppp = tp/(tp+fp)
npp = tn/(tn+fn)
hitrate = (tp+tn)/(tp+tn+fp+fn)
result <- paste("Sensitivity = ", round(sensitivity, n) ,
"\nSpecificity = ", round(specificity, n),
"\nPositive Predictive Value = ", round(ppp, n),
"\nNegative Predictive Value = ", round(npp, n),
"\nAccuracy = ", round(hitrate, n), "\n", sep="")
cat(result)
}
performance(logit.perf)
performance(dtree.perf)
performance <- function(table, n=2){
if(!all(dim(table) == c(2,2)))
stop("Must be a 2 x 2 table")
tn = table[1,1]
fp = table[1,2]
fn = table[2,1]
tp = table[2,2]
sensitivity = tp/(tp+fn)
specificity = tn/(tn+fp)
ppp = tp/(tp+fp)
npp = tn/(tn+fn)
hitrate = (tp+tn)/(tp+tn+fp+fn)
result <- paste("Sensitivity = ", round(sensitivity, n) ,
"\nSpecificity = ", round(specificity, n),
"\nPositive Predictive Value = ", round(ppp, n),
"\nNegative Predictive Value = ", round(npp, n),
"\nAccuracy = ", round(hitrate, n), "\n", sep="")
cat(result)
}
performance(logit.perf)
performance(dtree.perf)
performance(ctree.perf)
performance(forest.perf)
performance(logit.perf)
performance(dtree.perf)
performance(ctree.perf)
performance(forest.perf)
knitr::opts_chunk$set(echo = TRUE)
demo<- read.table("demo.txt")
head(demo)
knitr::opts_chunk$set(echo = TRUE)
df<- read.csv("poisson.csv")
library(ggplot2)
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df$prog,aes(x=num_awards)) + geom_histogram()
library(lattice)
df<- read.csv("poisson.csv")
library(ggplot2)
library(lattice)
data(df, package="lattice")
ggplot(df$prog,aes(x=num_awards)) + geom_histogram()
df<- read.csv("poisson.csv")
library(ggplot2)
library(lattice)
data(df$prog, package="lattice")
ggplot(df$prog,aes(x=num_awards)) + geom_histogram()
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards)) + geom_histogram()
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards,y=prog)) + geom_histogram()
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards)) + geom_histogram(fill="blue")
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards),fill=prog) + geom_histogram(fill="blue")
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards),fill=df$prog) + geom_histogram(fill="blue")
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards),fill=df$prog) + geom_histogram()
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards,fill=df$prog)) + geom_histogram()
df<- read.csv("poisson.csv")
library(ggplot2)
ggplot(df,aes(x=num_awards,fill=prog)) + geom_histogram()
ggplot(df,aes(x=num_awards,fill=prog)) + geom_histogram(binwidth=1)
ggplot(df,aes(x=num_awards,fill=prog)) +geom_bar(position="dodge")
prog<-factor(df$prog)
df$prog<-factor(df$prog)
df<- read.csv("poisson.csv")
library(ggplot2)
df$prog<-factor(df$prog)
ggplot(df,aes(x=num_awards,fill=prog)) + geom_histogram(binwidth=1)
ggplot(df,aes(x=num_awards,fill=prog)) +geom_bar(position="dodge")
library(knitr)
\documentclass[12pt, letterpaper, twoside]{article}
\usepackage[utf8]{inputenc}
\title{Study}
\author{Patrick Brogan}
\date{August 2022}
\begin{document}
\maketitle
\begin{abstract}
One-paragraph summary of the entire study – typically no more than 250 words in length (and in many cases it is well shorter than that), the Abstract provides an overview of the study.
\end{abstract}
\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}
What is the topic and why is it worth studying? – the first major section of text in the paper, the Introduction commonly describes the topic under investigation, summarizes or discusses relevant prior research (for related details, please see the Writing Literature Reviews section of this website), identifies unresolved issues that the current research will address, and provides an overview of the research that is to be described in greater detail in the sections to follow.
\section*{Methods}
\addcontentsline{toc}{section}{Methods}
What did you do? – a section which details how the research was performed.  It typically features a description of the participants/subjects that were involved, the study design, the materials that were used, and the study procedure.  If there were multiple experiments, then each experiment may require a separate Methods section.  A rule of thumb is that the Methods section should be sufficiently detailed for another researcher to duplicate your research.
\section*{Results}
\addcontentsline{toc}{section}{Results}
What did you find? – a section which describes the data that was collected and the results of any statistical tests that were performed.  It may also be prefaced by a description of the analysis procedure that was used. If there were multiple experiments, then each experiment may require a separate Results section.
\section*{Discussion}
What is the significance of your results? – the final major section of text in the paper.  The Discussion commonly features a summary of the results that were obtained in the study, describes how those results address the topic under investigation and/or the issues that the research was designed to address, and may expand upon the implications of those findings.  Limitations and directions for future research are also commonly addressed.
\section*{References}
List of articles and any books cited – an alphabetized list of the sources that are cited in the paper (by last name of the first author of each source).  Each reference should follow specific APA guidelines regarding author names, dates, article titles, journal titles, journal volume numbers, page numbers, book publishers, publisher locations, websites, and so on (for more information, please see the Citing References in APA Style page of this website).
\end{document}
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
\begin{document}
summary(cars)
begin{document}
print(xtab, include.rownames = FALSE)
library(xtable)
n <- 10
dat <- data.frame(normal = rnorm(n),
poisson = rpois(n, lambda = 4),
gamma = rgamma(n, scale = 2, shape = 2))
xtab <- xtable(dat, digits = c(0, 3, 0, 3))
print(xtab, include.rownames = FALSE)
install.packages("xtable")
library(xtable)
n <- 10
dat <- data.frame(normal = rnorm(n),
poisson = rpois(n, lambda = 4),
gamma = rgamma(n, scale = 2, shape = 2))
xtab <- xtable(dat, digits = c(0, 3, 0, 3))
print(xtab, include.rownames = FALSE)
View(xtab)
setwd("~/GitHub/Project/course-paper-or-presentation-MichaelMarcaccio/Data")
